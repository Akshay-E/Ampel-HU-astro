{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f44e097",
   "metadata": {},
   "source": [
    "An alert filter (Ampel Tier 0) works on a single stream of incoming data, deciding based on its content whether a candidate should be rejected or added to the database for further analysis.\n",
    "\n",
    "A filter is functionally a python class which implements an abstract filter class through implementing the `process` method. This recieves an alert as input and makes the bool choice `True|False` about whether to save.\n",
    "\n",
    "Notes:\n",
    "- The `DecentFilter` is created as a general use ZTF alert filter for extragalactic transients and also includes an online star-veto using the Gaia catalog:\n",
    "https://github.com/AmpelProject/Ampel-ZTF/blob/master/ampel/ztf/t0/DecentFilter.py. This is a flexible starting point for various transient studies.\n",
    "- What happens after a transient is accepted depends on the T2 and T3 channel definition. Advanced users can make use of filter exit codes to fine-tune this process for individual events.\n",
    "- An ampel filter is exposed to _all_ incoming alerts and need to be efficiently setup. Quick  checks on basic alert properites should be done first, and more complex comparisons last. \n",
    "- Once an object has been accepted into the AMPEL live DB, new observations of the same object can be set to be saved irrespectively of subsequent filter evaluations through the `autocomplete` feature.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4d474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the archive token which can be obtained from https://ampel.zeuthen.desy.de/live/dashboard/tokens\n",
    "# In order to retrieve ZTF partnership alerts your token needs to have the appropriate access\n",
    "token = os.environ[\"ARCHIVE_TOKEN\"]   # I have mine stored\n",
    "header = {\"Authorization\": \"bearer \"+token}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b57d5a",
   "metadata": {},
   "source": [
    "##### 1. Obtaining a stream of alerts \n",
    "\n",
    "This demonstration will be carried out using a pre-selected set of alerts taken from one ZTF field, and with a set of minimal properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://ampel.zeuthen.desy.de/api/ztf/archive/v3/streams/from_query?programid=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a4bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base alert query: \n",
    "# - For ZTF operations 2020 (JD selection).\n",
    "# - At least 5 detection, the last has to be positive, and Real-Bogus>0.3\n",
    "# - In a specific ZTF field [1]\n",
    "query = {\n",
    "  \"jd\": {\n",
    "    \"$gt\": 2458849.5,\n",
    "    \"$lt\": 2458859.5,\n",
    "  },\n",
    "  \"candidate\": {\n",
    "    \"rb\": {\n",
    "      \"$gt\": 0.3\n",
    "    },\n",
    "    \"ndethist\": {\n",
    "      \"$gt\": 4,\n",
    "    },\n",
    "    \"isdiffpos\": {\"$in\": [\"t\", \"1\"]},\n",
    "    \"field\": {\"$in\":[773]},\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e221e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(endpoint, headers=header, json=query )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01b054",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not response.ok:\n",
    "    print( 'Query creation failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The full response contains the resume token as well as the chunk size, i.e.\n",
    "# how many alerts will be return in each call to the alert iterator.\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d18d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_token = response.json()['resume_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda60240",
   "metadata": {},
   "source": [
    "At this point the alert archive will start the process of staging alerts for release. This process takes a few min (length depending on query size), during which time the resume_token will stay locked. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef58015",
   "metadata": {},
   "source": [
    "##### 2. Create a transient filter\n",
    "\n",
    "We will here implement a filter class for ZTF alerts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7799754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampel.protocol.AmpelAlertProtocol import AmpelAlertProtocol\n",
    "from ampel.abstract.AbsAlertFilter import AbsAlertFilter\n",
    "from ampel.log.AmpelLogger import AmpelLogger\n",
    "\n",
    "\n",
    "class DemoFilter(AbsAlertFilter):\n",
    "    \"\"\"\n",
    "    Sample filter based on the following criteria for acceptance:\n",
    "    - At least 5 detections in at least 2 bands.\n",
    "    - RealBogus: either one detection >0.65 or 5 >0.3.\n",
    "    - At most one detection >1yr older than the most recent.\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    min_ndet: int\n",
    "    min_bands: int = 2\n",
    "    min_maxrb: float = 0.65  # One det with RB larger than this OR\n",
    "    min_goodrb_det: int = 3  # At least this many \"ok\" detections (RB>0.3)\n",
    "    max_old_det: int = 2     # Max number of \"old\" (>1yr) detections in the ALERT package.\n",
    "    max_archive_tspan: float = 365.  # Max age since first detection\n",
    "    \n",
    "\n",
    "    # Override\n",
    "    def process(self, alert: AmpelAlertProtocol) -> None | bool | int:\n",
    "        \"\"\"\n",
    "        Mandatory implementation.\n",
    "        To exclude the alert, return *None*\n",
    "        To accept it, either return\n",
    "        * self.on_match_t2_units\n",
    "        * or a custom combination of T2 unit names\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        # CUT ON THE HISTORY OF THE ALERT\n",
    "        #################################\n",
    "        \n",
    "        # Get real detections (with candid)\n",
    "        pps = [el for el in alert.datapoints if el.get(\"candid\") is not None]\n",
    "        \n",
    "        # Sufficient number of detections\n",
    "        if len(pps) < self.min_ndet:\n",
    "            self.logger.debug(None, extra={\"nDet\": len(pps)})\n",
    "            return None\n",
    "        # Sufficient number of filters\n",
    "        if len( set([el['fid'] for el in pps]) ) < self.min_bands:\n",
    "            self.logger.debug(None, extra={\"nBands\": len(set([el['fid'] for el in pps]))}) \n",
    "            return None\n",
    "        \n",
    "        # RealBogus\n",
    "        if len( [1 for el in pps if el['rb']>=self.min_maxrb] )==0:\n",
    "            self.logger.debug(None, extra={\"maxRB\": max([el['rb'] for el in pps])}) \n",
    "            return None\n",
    "        if len( [1 for el in pps if el['rb']>=0.3] )<self.min_goodrb_det:\n",
    "            self.logger.debug(None, extra={\"nbrGoodRB\": len( [1 for el in pps if el['rb']>=0.3] )}) \n",
    "            return None\n",
    "        \n",
    "\n",
    "        # Detection history - in the ALERTS!\n",
    "        detection_jds = [el['jd'] for el in pps]\n",
    "        latest_jd = max(detection_jds)\n",
    "        old_js = [ el['jd'] for el in pps if (latest_jd-el['jd'])>365. ]\n",
    "        if len(old_js)>self.max_old_det:\n",
    "            self.logger.debug(None, extra={\"nbrOldDet\": len(old_js) }) \n",
    "            return None\n",
    "        \n",
    "        # Cut on archive length\n",
    "        archive_start_jd = pps[0]['jdstarthist']\n",
    "        archive_tspan = latest_jd - archive_start_jd\n",
    "        if not (self.max_archive_tspan > archive_tspan):\n",
    "            self.logger.debug(None, extra={'archive_tspan': archive_tspan})\n",
    "            return None\n",
    "\n",
    "        # An alert which made it this far is accepted!\n",
    "        return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can update filter parameters, or leave the defaults. \n",
    "# Parameters without defaults have to be set\n",
    "filter_config = {\n",
    "    'min_ndet': 5,       # Necessary parameter\n",
    "    'max_old_det': 1,    # Override default\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0filter = DemoFilter( **filter_config, logger=AmpelLogger.get_logger() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c20cf5",
   "metadata": {},
   "source": [
    "##### 3. Run filter on the alerts returned from the alert query\n",
    "\n",
    "For this we need a `ZTFArchiveAlertLoader` (see query/alert notebook) as well as an `AlertSupplier` for ZTF alerts. The latter reshapes raw ZTF data to a general alert format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ampel.ztf.t0.load.ZTFArchiveAlertLoader import ZTFArchiveAlertLoader\n",
    "from ampel.ztf.alert.ZiAlertSupplier import ZiAlertSupplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556e422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The loader config contains the resume_token as stream identifier\n",
    "config = {'archive':\"https://ampel.zeuthen.desy.de/api/ztf/archive/v3\", \n",
    "          \"stream\":resume_token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf5c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accepted_alerts = []\n",
    "alertcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d720a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    alertloader = ZTFArchiveAlertLoader(**config)\n",
    "    for alert in alertloader.get_alerts():\n",
    "        alertcount += 1\n",
    "        print(alert['objectId'], alert['candidate']['jd'])\n",
    "        filter_accept = t0filter.process( ZiAlertSupplier.shape_alert_dict( alert, [] ) )\n",
    "        if filter_accept:\n",
    "            accepted_alerts.append(alert)\n",
    "            print('... accepted')\n",
    "except requests.exceptions.HTTPError as e:\n",
    "    status_code = e.response.status_code\n",
    "    if status_code==423:\n",
    "        print('HTTP error {}: likely caused by server staging process. Wait and try again.'.format(status_code) )\n",
    "    else:\n",
    "        raise e\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67d2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_objects = len( set([alert.get(\"objectId\") for alert in accepted_alerts]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53a812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parsed {} alerts, out of which alerts for {} objects across {} alerts were accepted by the filter'.format(alertcount,unique_objects, len(accepted_alerts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae838871",
   "metadata": {},
   "source": [
    "Accepted alerts are in a live AMPEL instance saved into the DB ans tickets for feature calculations (T2s) are created. The processing layer of AMPEL will in parallel start to process these tickets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
